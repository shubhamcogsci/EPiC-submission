{"metadata":{"colab":{"provenance":[{"file_id":"14D9kd_79pTt7-faNTQYLI_FhbSeU4moB","timestamp":1682556875039}]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"TPU","gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["### This file will basically import pretrained model weights and perform prediction on a folder of files."],"metadata":{"id":"ID5ASdsResNu"}},{"cell_type":"code","source":["import numpy as np\n","import os\n","import pandas as pd\n","import sklearn\n","from  sklearn.model_selection import train_test_split\n","from sklearn import datasets, linear_model, metrics\n","import glob\n","from sklearn.metrics import mean_squared_error\n","import neurokit2 as nk\n","import joblib\n","\n","# !pip install neurokit2 joblib"],"metadata":{"id":"024TF_d4cD1X","execution":{"iopub.status.busy":"2023-04-26T23:34:00.679312Z","iopub.execute_input":"2023-04-26T23:34:00.679813Z","iopub.status.idle":"2023-04-26T23:34:04.008555Z","shell.execute_reply.started":"2023-04-26T23:34:00.679771Z","shell.execute_reply":"2023-04-26T23:34:04.007055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load model to predict arousal"],"metadata":{"id":"T4MDKuleLPHg"}},{"cell_type":"code","source":["regressionTree_asl = joblib.load(\"path/to/pretrained/model/weights/for/arousal\")    #weights are given in our github repo, whose path could be found from readme"],"metadata":{"id":"gV7yUqcKLPHn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load model to predict velence"],"metadata":{"id":"9r6bSAB94iee"}},{"cell_type":"code","source":["regressionTree_vel = joblib.load(\"path/to/pretrained/model/weights/for/velence\")    #weights are given in our github repo, whose path could be found from readme"],"metadata":{"id":"zgKRJkPi4qNN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Cleaning, Feature extraction and Testing "],"metadata":{"id":"bz8fGnlg7JMO"}},{"cell_type":"code","source":["directory = \"path/to/folder/of/test/csvs\" + \"/\"                                    #folder of csvs,folder of test physiology csvs in our case\n","directory_to_store = \"path/where/you/want/to/save/output/predictions\" + \"/\"        #output folder path\n","csv_files = glob.glob(directory)\n","csvname = os.listdir(directory)"],"metadata":{"id":"FCPCI9BwVDNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for csv in csvname:\n","\n","    df = pd.read_csv(directory + csv)\n","\n","    #data cleaning and feature extraction using neurokit library\n","    temp_ecg= nk.ecg_process(df.ecg,1000)\n","    temp_bvp= nk.ppg_process(df.bvp,1000)\n","    temp_rsp= nk.rsp_process(df.rsp,1000)\n","    temp_gsr= nk.eda_process(df.gsr,1000)\n","\n","    temp_emg_coru= nk.emg_process(df.emg_coru,1000)\n","    temp_emg_coru[0].EMG_Amplitude*=100     \n","\n","    temp_emg_zygo= nk.emg_process(df.emg_zygo,1000)\n","    temp_emg_zygo[0].EMG_Amplitude*=100 \n","\n","    temp_emg_trap= nk.emg_process(df.emg_trap,1000)\n","    temp_emg_trap[0].EMG_Amplitude*=100   \n","\n","    df.skt.fillna(method='pad')\n","    temp_skt=nk.ppg_process(df.skt,1000)\n","    temp_skt[0].PPG_Clean+=df.skt.mean() \n","\n","    df.insert(2, \"Heart_Rate\",temp_ecg[0].ECG_Rate, True)\n","    df.insert(4, \"BVP_clean\",temp_bvp[0].PPG_Clean, True)\n","    df.insert(6, \"GSR_clean_phasic\",temp_gsr[0].EDA_Phasic, True)\n","    df.insert(8, \"RR_clean\",temp_rsp[0].RSP_Rate, True)\n","    df.insert(10, \"skt_clean\",temp_skt[0].PPG_Clean, True)\n","    df.insert(12, \"zygo_clean\",temp_emg_zygo[0].EMG_Amplitude, True)\n","    df.insert(14, \"coru_clean\",temp_emg_coru[0].EMG_Amplitude, True)\n","    df.insert(16, \"trap_clean\",temp_emg_trap[0].EMG_Amplitude, True)\n","    \n","\n","    #removing first 10 second and last 10 second data, but we have trained model on 2 second delay because as per our findings it gives better results because humans delay to respond in joystick\n","    #so we remove first 8 seconds and last 12 seocnds data\n","    \n","    df = df.iloc[8000:-12000,:]\n","    df = df.reset_index(drop=True)\n","    df = df.drop(columns = [\"time\",\"ecg\",\"bvp\",\"gsr\",\"rsp\",\"skt\",\"emg_zygo\",\"emg_coru\",\"emg_trap\"], axis = 1)   #dropping unnecessary columns\n","  \n","    #down sampling our data to 200Hz\n","    array = range(0, len(df),5) \n","    df = df.iloc[array]\n","    df = df.reset_index(drop=True)   \n","    \n","    #prediction of valence and arousal using loaded models\n","    arousal = regressionTree_asl.predict(df)\n","    valence = regressionTree_vel.predict(df)\n","    \n","    # storing values in desired path, which is \"directory_to_store\"\n","    p_df = pd.DataFrame({\"arousal\":arousal,\"valence\":valence})\n","    array1 = range(0, len(p_df),10)\n","    df1 = p_df.iloc[array1]\n","    df1 = df1.reset_index(drop=True) \n","    df1.insert(0,\"time\",range(10000,10000+(len(df1)*50),50))\n","    df1[\"arousal\"] = round(df1[\"arousal\"],3)\n","    df1[\"valence\"] = round(df1[\"valence\"],3)\n","    df1.to_csv(directory_to_store + csv,index = False)\n","\n","  "],"metadata":{"id":"grnSxk-lLPHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8x0fGTCJ7ZX8"},"execution_count":null,"outputs":[]}]}
